<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>序列模型 | Echo Ji</title>
    <meta name="description" content=" 面试前整理的一些自己不熟悉的知识点，好想拥有一个硬盘一样的脑袋，可以不忘掉的那种。 --&gt;
循环神经网络
全称 Recurrent Neural Networks, RNN，它可以应对多对多，多对一，一对一，一对多的任务，其模型可以表示为下图。
    &lt;img :src=&quot;$withBas ...">
    <link rel="icon" href="/blogs/favicon.ico">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    
    <link rel="preload" href="/blogs/assets/css/0.styles.606e9f23.css" as="style"><link rel="preload" href="/blogs/assets/js/app.67f6c0ad.js" as="script"><link rel="preload" href="/blogs/assets/js/4.7c2c95e9.js" as="script"><link rel="preload" href="/blogs/assets/js/5.8b86248a.js" as="script"><link rel="preload" href="/blogs/assets/js/40.00614145.js" as="script"><link rel="prefetch" href="/blogs/assets/js/1.e76662eb.js"><link rel="prefetch" href="/blogs/assets/js/10.c6aeaa4b.js"><link rel="prefetch" href="/blogs/assets/js/11.82df316d.js"><link rel="prefetch" href="/blogs/assets/js/12.eab284d2.js"><link rel="prefetch" href="/blogs/assets/js/13.cd8e489a.js"><link rel="prefetch" href="/blogs/assets/js/14.a3f84c0c.js"><link rel="prefetch" href="/blogs/assets/js/15.9bdbb339.js"><link rel="prefetch" href="/blogs/assets/js/16.f4317575.js"><link rel="prefetch" href="/blogs/assets/js/17.fa69ee94.js"><link rel="prefetch" href="/blogs/assets/js/18.d453431b.js"><link rel="prefetch" href="/blogs/assets/js/19.064e46d1.js"><link rel="prefetch" href="/blogs/assets/js/20.c1c3c0e8.js"><link rel="prefetch" href="/blogs/assets/js/21.04422038.js"><link rel="prefetch" href="/blogs/assets/js/22.513643ab.js"><link rel="prefetch" href="/blogs/assets/js/23.c151a0a2.js"><link rel="prefetch" href="/blogs/assets/js/24.2308ffa1.js"><link rel="prefetch" href="/blogs/assets/js/25.ead0a5d4.js"><link rel="prefetch" href="/blogs/assets/js/26.0ef4d587.js"><link rel="prefetch" href="/blogs/assets/js/27.f8f8a9f8.js"><link rel="prefetch" href="/blogs/assets/js/28.f37568cf.js"><link rel="prefetch" href="/blogs/assets/js/29.cc7c7c41.js"><link rel="prefetch" href="/blogs/assets/js/30.61a41790.js"><link rel="prefetch" href="/blogs/assets/js/31.4f93a2f0.js"><link rel="prefetch" href="/blogs/assets/js/32.3007c773.js"><link rel="prefetch" href="/blogs/assets/js/33.015d00b6.js"><link rel="prefetch" href="/blogs/assets/js/34.5b8ce30c.js"><link rel="prefetch" href="/blogs/assets/js/35.2c376d79.js"><link rel="prefetch" href="/blogs/assets/js/36.68b803bc.js"><link rel="prefetch" href="/blogs/assets/js/37.61275c14.js"><link rel="prefetch" href="/blogs/assets/js/38.e3e5c80e.js"><link rel="prefetch" href="/blogs/assets/js/39.d17125e0.js"><link rel="prefetch" href="/blogs/assets/js/41.dc745971.js"><link rel="prefetch" href="/blogs/assets/js/42.792f151c.js"><link rel="prefetch" href="/blogs/assets/js/43.e40bff08.js"><link rel="prefetch" href="/blogs/assets/js/6.0217efa2.js"><link rel="prefetch" href="/blogs/assets/js/7.c3500f45.js"><link rel="prefetch" href="/blogs/assets/js/8.dc8dfe73.js"><link rel="prefetch" href="/blogs/assets/js/9.119b9b2f.js"><link rel="prefetch" href="/blogs/assets/js/vuejs-paginate.e1db4a3b.js">
    <link rel="stylesheet" href="/blogs/assets/css/0.styles.606e9f23.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="vuepress-theme-blog__global-layout"><section id="header-wrapper"><header id="header"><div class="header-wrapper"><div class="title"><a href="/blogs/" class="nav-link home-link">Echo Ji </a></div> <div class="header-right-wrap"><ul class="nav"><li class="nav-item"><a href="/blogs/" class="nav-link">Blog</a></li><li class="nav-item"><a href="/blogs/tag/" class="nav-link">Tags</a></li></ul> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></div></header></section> <div id="mobile-header"><div class="mobile-header-bar"><div class="mobile-header-title"><a href="/blogs/" class="nav-link mobile-home-link">Echo Ji </a> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></div> <div class="mobile-menu-wrapper"><hr class="menu-divider"> <ul class="mobile-nav"><li class="mobile-nav-item"><a href="/blogs/" class="nav-link">Blog</a></li><li class="mobile-nav-item"><a href="/blogs/tag/" class="nav-link">Tags</a></li> <li class="mobile-nav-item"><!----></li></ul></div></div></div> <div class="content-wrapper"><div id="vuepress-theme-blog__post-layout"><div class="vuepress-blog-theme-content"><h1 class="post-title">序列模型</h1> <div class="post-meta"><div class="post-meta-author"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-navigation"><polygon points="3 11 22 2 13 21 11 13 3 11"></polygon></svg> Echo
    <span>   in Beijing</span></div> <div class="post-meta-date"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg> 2020-09-18
  </div> <ul class="post-meta-tags"><li class="post-tag" data-v-d832e844><a href="/blogs/tag/序列模型" data-v-d832e844> 序列模型 </a></li><li class="post-tag" data-v-d832e844><a href="/blogs/tag/循环神经网络" data-v-d832e844> 循环神经网络 </a></li><li class="post-tag" data-v-d832e844><a href="/blogs/tag/深度学习" data-v-d832e844> 深度学习 </a></li></ul></div> <div class="content__default"><h2 id="循环神经网络"><a href="#循环神经网络" class="header-anchor">#</a> 循环神经网络</h2> <p>全称 Recurrent Neural Networks, RNN，它可以应对多对多，多对一，一对一，一对多的任务，其模型可以表示为下图。</p> <div style="text-align:center;"><img src="/blogs/2020-09-18-rnn-f.png" alt="2020-09-18-rnn-f" style="margin:0 auto;"></div> <p>传统的 RNN 存在一个限制，某一时刻的预测仅使用了前面序列的信息，没有用到后面序列的信息，双向 RNN 可以解决这个问题（BRNN）。</p> <p>此外，基本的 RNN 存在梯度消失的问题，而且很难捕捉到长期的依赖关系。</p> <p>于是有了两个变体 GRU 和 LSTM。</p> <h3 id="gru-和-lstm"><a href="#gru-和-lstm" class="header-anchor">#</a> GRU 和 LSTM</h3> <p>GRU 只有两个门，是更加简单的模型，计算性能上更快，可以创建更大规模的网络。
LSTM 有三个门，更加强大和灵活，历史更加悠久。</p> <h3 id="深层-rnn"><a href="#深层-rnn" class="header-anchor">#</a> 深层 RNN</h3> <p>堆叠隐藏层，延迟对 y 的预测。</p> <h2 id="词嵌入"><a href="#词嵌入" class="header-anchor">#</a> 词嵌入</h2> <p>词嵌入（word embedding）是语言表示的一种方法，区别于 One-hot 表示，它可以让算法自动理解一些类似的词，比如男人对女人，国王对王后。</p> <p>通过 t-SNE 算法可以将高维数据映射到平面中进行可视化。</p> <p>一般情况下，自己的任务中数据集较小，需要使用迁移学习来优化性能，使用词嵌入进行迁移学习的流程如下：</p> <ul><li>从大量文本中学习词嵌入（或者下载预训练词嵌入模型）</li> <li>迁移到只有少量标注数据的任务中来</li> <li>此外，可以选择对词嵌入模型进行 finetune</li></ul> <p>词嵌入可以帮助我们进行类比推理，比如 <code>男人 - 女人 = 国王 - ?</code>，通过词嵌入，可以得到 <code>? = 王后</code>。
那么如何得到有效的词嵌入呢？</p> <h3 id="学习词嵌入矩阵"><a href="#学习词嵌入矩阵" class="header-anchor">#</a> 学习词嵌入矩阵</h3> <p>词嵌入向量通常会被构造成词嵌入矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05764em;">E</span></span></span></span>，每列为一个词向量 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">e_x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">e</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>。</p> <p>可以通过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05764em;">E</span></span></span></span> 与该词的 One-hot 编码 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>o</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">o_x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">o</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 得到 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">e_x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">e</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>，即 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>x</mi></msub><mo>=</mo><mi>E</mi><mo>⋅</mo><msub><mi>o</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">e_x = E \cdot o_x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">e</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mbin">⋅</span><span class="mord"><span class="mord mathit">o</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>。
通常以语言模型为载体进行词嵌入的学习，给定多个词预测一个目标词，让给定的词通过 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>e</mi><mi>x</mi></msub><mo>=</mo><mi>E</mi><mo>⋅</mo><msub><mi>o</mi><mi>x</mi></msub></mrow><annotation encoding="application/x-tex">e_x = E \cdot o_x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">e</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="mbin">⋅</span><span class="mord"><span class="mord mathit">o</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 转化为词向量，然后输入到神经网络（比如 <code>Softmax</code> 分类器）中预测目标词，进而优化词嵌入矩阵 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05764em;">E</span></span></span></span>。如下图所示（图片来自于 Andrew Ng）。</p> <div style="text-align:center;"><img src="/blogs/2020-09-18-lang-model.png" alt="2020-10-13-lang-model" style="margin:0 auto;"></div> <p>给定的多个词可以是目标词的上下文中的任意词，比如前 4 个，前后 4 个，前一个或者 5-邻域内任意一个词等。</p> <h4 id="word2vec"><a href="#word2vec" class="header-anchor">#</a> Word2Vec</h4> <p>Word2Vec 有两种很常见的方式：Skip-Gram 模型和连续词袋（CBOW）模型。</p> <p>其主要还是基于前文的方法构建 <code>Softmax</code> 分类器，但是局限在于当 <code>Softmax</code> 类别多的时候计算速度很慢，因此想要扩大词汇表就更加困难了。</p> <p>解决方案有两种：分级 <code>Softmax</code> 分类器和负采样。</p> <ul><li>分级 <code>Softmax</code> 分类器将构建树状的二分类器，使得计算成本与词汇表的对数成正比</li> <li>负采样则对每一对 <code>上下文-目标词</code> 构建 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">K</span></span></span></span> 个负样本，每次只训练 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">K+1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="mbin">+</span><span class="mord mathrm">1</span></span></span></span> 个二分类器，使得计算成本成为常数</li></ul> <p>此外，GloVe 算法也是一种计算词嵌入的方法。</p></div> <!----> <hr> <!----></div> <div class="sticker vuepress-toc"><div class="vuepress-toc-item vuepress-toc-h2 active"><a href="#循环神经网络" title="循环神经网络">循环神经网络</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#gru-和-lstm" title="GRU 和 LSTM">GRU 和 LSTM</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#深层-rnn" title="深层 RNN">深层 RNN</a></div><div class="vuepress-toc-item vuepress-toc-h2"><a href="#词嵌入" title="词嵌入">词嵌入</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#学习词嵌入矩阵" title="学习词嵌入矩阵">学习词嵌入矩阵</a></div></div></div></div> <footer class="footer" data-v-582f9766><div class="footer-left-wrap" data-v-582f9766><ul class="contact" data-v-582f9766><li class="contact-item" data-v-582f9766><a href="https://github.com/Echo-Ji" target="_blank" rel="noopener noreferrer" class="nav-link external" data-v-582f9766><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github" data-v-582f9766><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22" data-v-582f9766></path></svg>
          
        </a></li><li class="contact-item" data-v-582f9766><a href="/blogs/2020/09/18/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/bh1506jjh@gmail.com.html" class="nav-link" data-v-582f9766><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-mail" data-v-582f9766><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z" data-v-582f9766></path><polyline points="22,6 12,13 2,6" data-v-582f9766></polyline></svg>
          
        </a></li></ul></div> <div class="footer-right-wrap" data-v-582f9766><ul class="copyright" data-v-582f9766><li class="copyright-item" data-v-582f9766><a href="https://github.com/Echo-Ji" target="_blank" rel="noopener noreferrer" class="nav-link external" data-v-582f9766>Echo Ji © 2020</a></li></ul></div></footer></div><div class="global-ui"></div></div>
    <script src="/blogs/assets/js/app.67f6c0ad.js" defer></script><script src="/blogs/assets/js/4.7c2c95e9.js" defer></script><script src="/blogs/assets/js/5.8b86248a.js" defer></script><script src="/blogs/assets/js/40.00614145.js" defer></script>
  </body>
</html>
